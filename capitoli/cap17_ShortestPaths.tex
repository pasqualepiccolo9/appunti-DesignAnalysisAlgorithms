\chapter{Shortest Paths}
\label{cap:ShortestPaths}

Come abbiamo già visto, la ricerca in ampiezza (BFS) permette di trovare il cammino minimo in un grafo quando tutti gli archi sono considerati equivalenti. Tuttavia, in molte applicazioni reali questa condizione non è soddisfatta: per individuare il percorso più rapido tra due città o il tragitto più veloce per un pacchetto dati in rete, è necessario distinguere tra archi con caratteristiche diverse. Infatti, in questi contesti accade che alcune distanze tra le città saranno probabilmente molto più grandi di altre, e alcune connessioni in una rete di computer sono tipicamente molto più veloci di altre (ad esempio, alcune connessioni a bassa larghezza di banda contro connessioni ad alta velocità in fibra ottica). È quindi naturale considerare dei grafi pesatidove a ogni arco è associato un peso che ne rappresenta il costo o l'importanza.

\section{Weighted Graphs}
Un \textbf{weighted graph} (grafo pesato) è un grafo che ha un'etichetta numerica $w(e)$ associata a ciascun arco $e$, chiamata il peso (weight) dell'arco $e$. Per $e = (u,v)$, indichiamo il suo peso con la notazione $w(e) = w(u,v)$. 

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.9\textwidth]{immagini/ShortestPath/weighted_graph.png}
    \caption{Esempio di grafo pesato i cui vertici rappresentano i principali aeroporti degli Stati Uniti e i cui pesi degli archi rappresentano le distanze in miglia.}
    \label{fig:weighted_graph}
\end{figure}


\clearpage
\noindent
Sia $G$ un grafo pesato. La lunghezza (o peso) di un percorso $P$ è la somma dei pesi degli archi di $P$. Cioè, se $P = ((v_0,v_1), (v_1,v_2), \ldots , (v_{k-1},v_k))$, allora la lunghezza di $P$, indicata con $w(P)$, è definita come:

$$
w(P) = \sum_{i=1}^{k} w(v_{i-1}, v_i)
$$

\noindent
La \textbf{distanza} da un vertice $u$ a un vertice $v$ in $G$, indicata con $d(u,v)$, è la lunghezza di un percorso di lunghezza minima (chiamato anche \textbf{shortest path}) da $u$ a $v$, se tale percorso esiste.
Se non esiste alcun percorso da $u$ a $v$, allora utilizziamo la convenzione $d(u,v) = \infty$.

\paragraph{Proprietà di uno shortest path} 
\begin{enumerate}
    \item Un frammento di uno shortest path è anch'esso uno shortest path. Cioè, se $P$ è uno shortest path da $u$ a $v$ e $w$ è un vertice su $P$, allora il frammento di $P$ da $u$ a $w$ è uno shortest path da $u$ a $w$, e il frammento di $P$ da $w$ a $v$ è uno shortest path da $w$ a $v$.
    \item Gli shortest path da un vertice sorgente $s$ a tutti gli altri vertici costituiscono uno \textbf{shortest path spanning tree} (o shortest path tree) radicato in $s$.
\end{enumerate}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.8\textwidth]{immagini/ShortestPath/shortest_path_tree.png}
    \caption{Esempio di uno shortest path tree radicato nel vertice PVD.}
    \label{fig:ex_shortest_path}
\end{figure}

\paragraph{Problemi legati agli shortest path} 
\begin{itemize}
    \item $(u, v)$-shortest path\\
    Dati due vertici $u$ e $v$, trovare lo shortest path tra $u$ e $v$.
    \item Single source shortest path\\
    Dato un vertice $s$, trovare lo shortest path tree radicato in $s$ (ovvero, trova lo shortest path da $s$ a tutti gli altri vertici).
    \item All-pairs shortest paths\\
    Trovare gli shortest path per tutte le coppie di vertici nel grafo.
\end{itemize}

\noindent
Si noti come dalla soluzione del problema single source shortest path sia possibile ottenere la soluzione del problema \emph{$(u, v)$-shortest path}, mentre dalla soluzione del problema \emph{all-pairs shortest paths} sia possibile ottenere la soluzione di entrambi gli altri problemi. Tuttavia, è anche possibile risolvere il problema \emph{all-pairs shortest paths} eseguendo l'algoritmo per il \emph{single source shortest path} per ogni vertice del grafo.

\clearpage
\section{Algoritmo di Dijkstra}
Si vuole sviluppare un \textbf{algoritmo Greedy} per la risoluzione del problema \emph{single source shortest path}. L'idea principale nell'applicare il \emph{metodo Greedy} al problema degli shortest path da una singola sorgente è quella di eseguire una "ricerca in ampiezza pesata" a partire dal vertice sorgente $s$. In particolare, possiamo utilizzare il \emph{metodo Greedy} per sviluppare un algoritmo che cresce iterativamente una "nuvola" di vertici a partire da $s$, con i vertici che entrano nella nuvola in ordine di distanza da $s$. Quindi, in ogni iterazione, il prossimo vertice scelto è il vertice al di fuori della nuvola che è più vicino a $s$. L'algoritmo termina quando non ci sono più vertici al di fuori della nuvola (o quando quelli al di fuori della nuvola non sono connessi a quelli all'interno della nuvola, e quindi hanno distanza infinita), a quel punto abbiamo uno shortest path da $s$ a ogni vertice di $G$ raggiungibile da $s$. Questo approccio è un esempio semplice, ma comunque potente, del \emph{metodo Greedy}. 

L'applicazione del \emph{metodo Greedy} al problema degli shortest path da una singola sorgente porta a un algoritmo noto come \textbf{algoritmo di Dijkstra}.


\subsection{Edge Relaxation - Greedy Choice}
Definiamo un'etichetta $D(v)$ per ogni vertice $v$ in $V$, che utilizziamo per approssimare la distanza da $s$ a $v$ in $G$. Il significato di queste etichette è che $D(v)$ memorizzerà sempre la lunghezza del miglior percorso che abbiamo trovato finora da $s$ a $v$. Difatti, possiamo pensare a $D(v)$ come un lmite superiore della distanza minima reale $d(s,v)$. Inoltre, definiamo un insieme $C$, che rappresenta l'insieme di vertici nella "nuvola", ovvero quei vertici per i quali abbiamo già calcolato la distanza minima da $s$.

Inizialmente, definiamo $D(s) = 0$ e $D(v) = \infty$ per ogni $v \neq s$, e l'insieme $C$ come l'insieme vuoto. Ad ogni iterazione dell'algoritmo, selezioniamo un vertice $u$ non in $C$ con l'etichetta $D(u)$ più piccola, e lo aggiungiamo a $C$ (Generalmente, utilizzeremo una coda di priorità per selezionare tra i vertici al di fuori della nuvola, per via dell'efficienza del metodo \texttt{remove\_min()}). 

Nella prima iterazione, ovviamente, aggiungeremo $s$ a $C$. Una volta che un nuovo vertice $u$ viene aggiunto a $C$, aggiorniamo l'etichetta $D(v)$ di ogni vertice $v$ adiacente a $u$ e che è al di fuori di $C$, per riflettere il fatto che potrebbe esserci un nuovo e migliore modo per raggiungere $v$ passando per $u$. Questa operazione di aggiornamento è nota come \emph{rilassamento degli archi} (\textbf{edge relaxation}), poiché prende una vecchia stima e verifica se può essere migliorata per avvicinarsi al suo valore reale. L'operazione specifica di rilassamento degli archi è la seguente:

\vspace{1\baselineskip}
$\quad \quad \quad \textbf{Edge Relaxation:}$
$$
\begin{aligned}
    &\textbf{if } D(u) + w(u,v) < D(v) \textbf{ then} \\
    &\quad D(v) = D(u) + w(u,v)
\end{aligned}
$$

\clearpage
\subsection{Pseudocodice ed Esempio}
L'algoritmo di Dijkstra è descritto nel seguente pseudocodice:
\vspace{1\baselineskip}
\hrule
\begin{verbatim}
Input: A weighted graph G with nonnegative edge weights, 
       and a source vertex s of G.
Output: The length of a shortest path from s to v for each 
        vertex v of G.
1.  Algorithm ShortestPath(G, s):   
2.      Initialize D[s] = 0 and D[v] = +infinity for each vertex v != s
3.      Let a priority queue Q contain all the vertices of G 
            using the D labels as keys.
4.      while Q is not empty do
5.          // pull a new vertex u into the cloud
6.          u = value returned by Q.remove_min()
7.          for each vertex v adjacent to u such that v is in Q do
8.              // perform the relaxation procedure on edge (u,v)
9.              if D[u] + w(u,v) < D[v] then
10.                 D[v] = D[u] + w(u,v)
11.                 Change to D[v] the key of vertex v in Q.
12.     return the label D[v] of each vertex v                  
\end{verbatim}
\hrule 
\vspace{1\baselineskip}

\clearpage

\vspace{2\baselineskip}
\begin{figure}[!ht]
    \centering
    \includegraphics[width=1\textwidth]{immagini/ShortestPath/ex_dijkstra1.png}
    \label{fig:ex_dijkstra1}
\end{figure}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=1\textwidth]{immagini/ShortestPath/ex_dijkstra2.png}
    \caption{Esempio di esecuzione dell'algoritmo di Dijkstra. L'esempio inizia con il vertice sorgente $A$ già nella nuvola (in grigio chiaro) e con le etichette dei vertici adiacenti aggiornate. Ad ogni passo, il vertice con l'etichetta minima viene aggiunto alla nuvola e le etichette dei suoi vicini vengono aggiornate di conseguenza. Al termine dell'algoritmo, le etichette rappresentano le distanze minime da $A$ a tutti gli altri vertici. Gli archi in rosso al di fuori della nuvola rappresentano il percorso minimo attuale verso quel vertice. Gli archi in rosso nella nuvola rappresentano lo shortest path tree radicato in $A$. Gli archi tratteggiati sono quelli che non fanno parte dello shortest path tree.}
    \label{fig:ex_dijkstra2}
\end{figure}

\clearpage

\subsection{Dimostrazione della correttezza dell'algoritmo}
Potrebbe non essere immediatamente chiaro il motivo per cui l'algoritmo di Dijkstra trovi correttamente lo shortest path dal vertice di partenza $s$ a ogni altro vertice $u$ nel grafo. Perché la distanza minima da $s$ a $u$ è uguale al valore dell'etichetta $D(u)$ al momento in cui il vertice $u$ viene rimosso dalla coda di priorità $Q$ e aggiunto alla nuvola $C$? La risposta a questa domanda dipende dal fatto che \textbf{non ci siano archi con peso negativo nel grafo}, poiché ciò consente al metodo Greedy di funzionare correttamente.

\paragraph{Teorema:} Nell'algoritmo di Dijkstra, ogni volta che un vertice $v$ viene inserito nella soluzione $C$, l'etichetta $D(v)$ è uguale a $d(s, v)$, la lunghezza del percorso minimo da $s$ a $v$.

\paragraph{Dimostrazione:} Per dimostrare la tesi, procediamo per assurdo. Ipotizziamo che l'algoritmo sbagli per qualche vertice. Sia $z$ il \textbf{primo vertice} che l'algoritmo inserisce in $C$ tale che la sua etichetta sia errata, ovvero:
$$ D(z) > d(s, z) $$
Poiché $z$ è il \textit{primo} errore, significa che per tutti i vertici inseriti in $C$ prima di $z$, l'algoritmo ha calcolato la distanza corretta.

Esiste sicuramente un percorso minimo reale da $s$ a $z$ (altrimenti la distanza sarebbe $\infty$). Chiamiamo questo percorso $P$.
Consideriamo il momento esatto in cui l'algoritmo sta per inserire $z$ in $C$. Analizziamo il percorso $P$ partendo da $s$:
\begin{itemize}
    \item Il vertice sorgente $s$ appartiene già a $C$.
    \item Il vertice $z$ non appartiene a $C$.
    \item Di conseguenza, percorrendo il cammino $P$ da $s$ a $z$, deve necessariamente esistere un primo arco $(x, y)$ che attraversa il confine di $C$, tale che $x \in C$ (il vertice "dentro") e $y \notin C$ (il primo vertice "fuori").
\end{itemize}
Dunque, sia $y$ il \textbf{primo vertice} di $P$ che non appartiene a $C$, e sia $x$ il predecessore di $y$ lungo il percorso $P$. 
\begin{itemize}
    \item Poiché $y$ è il primo vertice fuori da $C$, ne consegue che $x$ deve trovarsi dentro $C$ (al limite $x$ potrebbe coincidere con $s$).
\end{itemize}


\clearpage
\begin{figure}[!ht]
    \centering
    \includegraphics[width=1\textwidth]{immagini/ShortestPath/dimostrazione.png}
    \caption{Rappresentazione grafica della dimostrazione della correttezza dell'algoritmo di Dijkstra.}
    \label{fig:dijkstra_proof}
\end{figure}

\noindent
Poiché $z$ è stato definito come il \textit{primo} vertice "sbagliato" aggiunto a $C$, e $x$ è stato aggiunto a $C$ prima di $z$, allora l'etichetta di $x$ è sicuramente corretta:
$$ D(x) = d(s, x) $$

\noindent
Quando $x$ è stato inserito in $C$, l'algoritmo ha eseguito la procedura di \textit{Edge Relaxation} sui suoi vertici adiacenti, incluso $y$. Questo aggiornamento garantisce che:
$$ D(y) \le D(x) + w(x, y) = d(s, x) + w(x, y) $$

\noindent
Poiché $x$ e $y$ sono vertici consecutivi sul percorso minimo $P$ (che è un percorso minimo globale), anche il sotto-percorso da $s$ a $y$ deve essere un percorso minimo. Pertanto:
$$ d(s, y) = d(s, x) + w(x, y) $$

\noindent
Combinando le due equazioni precedenti, otteniamo che l'etichetta di $y$ è già corretta al momento dell'estrazione di $z$:
$$ D(y) = d(s, y) $$

\noindent
Ora arriviamo al cuore della dimostrazione logica.
L'algoritmo di Dijkstra è \textit{greedy}: seleziona sempre il vertice fuori da $C$ con l'etichetta $D$ più piccola. In questo momento, sia $z$ che $y$ sono fuori da $C$ (sono nella coda $Q$), ma l'algoritmo ha scelto di estrarre $z$. Questo implica necessariamente che:
$$ D(z) \le D(y) $$

\noindent
Qui entra in gioco l'ipotesi fondamentale che non esistano archi con peso negativo. La distanza reale da $s$ a $z$ può essere scomposta nella distanza da $s$ a $y$ più la distanza rimanente da $y$ a $z$:
$$ d(s, z) = d(s, y) + d(y, z) $$

\noindent
Poiché i pesi sono non negativi, allora si ha che $d(y, z) \ge 0$. Di conseguenza:
$$ d(s, y) \le d(s, z) $$

\noindent
Mettiamo insieme la catena di disuguaglianze:
\begin{alignat*}{4}
    D(z)    &\le{}& D(y)    &\quad& \text{(} &\text{per la scelta greedy dell'algoritmo)} \\
    D(y)    &={} & d(s,y)  &\quad& \text{(} &\text{perché l'etichetta di $y$ è già corretta al momento dell'estrazione di $z$)} \\
    d(s,y)  &\le{}& d(s,z) &\quad& \text{(} &\text{perché i pesi sono non-negativi)}
\end{alignat*}

\noindent
Unendo tutto:
$$ D(z) \le d(s, z) $$

\noindent
Ma questo contraddice la nostra ipotesi iniziale per assurdo, secondo cui $D(z) > d(s, z)$.

\vspace{1\baselineskip}
\noindent
La contraddizione dimostra che non può esistere un "primo vertice sbagliato" $z$. Pertanto, per ogni vertice $v$ aggiunto a $C$, l'etichetta $D(v)$ rappresenta sempre la distanza minima corretta $d(s, v)$.



\subsection{Analisi della complessità}
Indichiamo con $n$ e $m$ rispettivamente il numero di vertici e di archi del grafo di input $G$. Assumiamo che i pesi degli archi possano essere sommati e confrontati in tempo costante. 

Per analizzare il tempo di esecuzione dell'algoritmo di Dijkstra dobbiamo innanzitutto specificare come viene rappresentato il grafo $G$ e come viene implementata la coda di priorità $Q$. Assumiamo di rappresentare il grafo $G$ tramite \emph{Adjacency List} o \emph{Adjacency Map}. In questo modo possiamo attraversare i vertici adiacenti a $u$ durante la fase di rilassamento in tempo proporzionale al loro numero. Pertanto, il tempo speso nella gestione del ciclo annidato \texttt{for}, e il numero di iterazioni di quel ciclo, è dato da:

$$
\sum_{u \text{ in } V} outdeg(u)
$$

\noindent
che è $O(m)$. Il ciclo esterno \texttt{while} viene eseguito $O(n)$ volte, poiché in ogni iterazione viene aggiunto un nuovo vertice alla nuvola. 

Tuttavia, per completare l'analisi dell'algoritmo, dobbiamo considerare anche l'implementazione della coda di priorità $Q$. La coda a priorità ad ogni iterazione dell'algoritmo contiene gli elementi che non sono ancora presenti nella soluzione $C$, per cui inizialmente vengono effettuate $n$ operazioni di inserimento in $Q$ (soluzione ancora vuota); queste sono le uniche operazioni di inserimento, quindi la dimensione massima della coda è $n$. In ciascuna delle $n$ iterazioni del ciclo \texttt{while}, viene effettuata una chiamata a \texttt{remove\_min()} per estrarre il vertice $u$ con l'etichetta $D$ più piccola da $Q$. Successivamente, per ogni vicino $v$ di $u$, viene eseguito un rilassamento dell'arco, che potrebbe comportare un aggiornamento della chiave di $v$ nella coda \footnote
{
    All'interno della coda a priorità $Q$, ciascun elemento ha per chiave il valore dell'etichetta $D(v)$ del vertice corrispondente $v$, e il valore associato è il vertice $v$ stesso. 
}. Pertanto, è necessario implementare una \emph{Adaptable Priority Queue}, in cui la chiave di un vertice $v$ può essere modificata utilizzando il metodo \texttt{update(l,k)}, dove $l$ è il \emph{locator} per l'elemento della coda associato al vertice $v$. Nel peggiore dei casi, potrebbe esserci un aggiornamento per ogni arco del grafo. Complessivamente, il tempo di esecuzione dell'algoritmo di Dijkstra è limitato dalla somma delle seguenti operazioni:
\begin{itemize}[nosep]
    \item $n$ operazioni di inserimento in $Q$.
    \item $n$ chiamate al metodo \texttt{remove\_min()} su $Q$.
    \item $m$ chiamate al metodo \texttt{update()} su $Q$.
\end{itemize}

\noindent
Se $Q$ è una Adaptable Priority Queue implementata come heap, allora ciascuna delle operazioni sopra descritte viene eseguita in tempo $O(\log n)$, e quindi il tempo complessivo per l'algoritmo di Dijkstra è $O((n + m) \log n)$. Si noti che se si desidera esprimere il tempo di esecuzione come funzione di $n$ soltanto, allora nel caso peggiore è $O(n^2 \log n)$.

\vspace{1\baselineskip}
\noindent
È possibile implementare la coda a priorità $Q$ utilizzando un'\emph{array non ordinato}. In questo caso, l'operazione di estrazione del minimo richiede $O(n)$ tempo, mentre l'aggiornamento delle chiavi può essere eseguito in tempo costante. Pertanto, il tempo totale di esecuzione dell'algoritmo di Dijkstra diventa $O(n^2 + m)$, che si semplifica a $O(n^2)$ per grafi semplici.

\subsubsection{Confronto tra le due implementazioni - Adaptable Priority Queue vs Array non ordinato}
Come abbiamo visto, abbiamo due possibili scelte per implementare la coda a priorità $Q$ nell'algoritmo di Dijkstra: una implementazione basata su heap, che porta a un tempo di esecuzione di $O((n + m) \log n)$, e una implementazione basata su array non ordinato, che porta a un tempo di esecuzione di $O(n^2)$. Dal momento che entrambe le implementazioni hanno lo stesso livello di complessità (a livello di codice), la scelta tra le due dipende principalmente dalla densità del grafo di input.

In generale, si preferisce l'implementazione basata su heap quando il grafo è sparso (ovvero, quando il numero di archi è abbastanza piccolo, e si ha $m < n^2 / \log n$). Si preferisce invece l'implementazione basata su array non ordinato quando il grafo è denso (ovvero, quando il numero di archi è vicino al massimo possibile, e si ha $m > n^2 / \log n$).


\begin{table}[h]
    \centering
    \renewcommand{\arraystretch}{1.2} 
    
    % Definizione colonne:
    % | l | -> Prima colonna: larghezza minima necessaria (adatta al contenuto)
    % X |   -> Seconda colonna: riempie lo spazio disponibile
    % X |   -> Terza colonna: riempie lo spazio disponibile
    \begin{tabularx}{\textwidth}{| l | X | X |}
        \hline
        % Prima riga: applico il grassetto manualmente qui
        \textbf{Implementation of the Priority Queue} & \textbf{Complexity} & \textbf{Usable for} \\
        \hline
        
        Binary Heap     & $O(m \log n)$     & $m < n^2 / \log n$ \\
        \hline
        
        Unordered Array & $O(n^2)$          & $m > n^2 / \log n$ \\
        \hline
        
        Fibonacci Heap  & $O(m + n \log n)$ & always \\
        \hline
    \end{tabularx}
    \caption{Si noti che esiste un'implementazione avanzata della coda a priorità, nota come \textbf{Fibonacci heap}, che può essere utilizzata per implementare l'algoritmo di Dijkstra in tempo $O(m + n \log n)$. Si tratta di un'implementazione più complessa, ma che offre prestazioni migliori in tutti i casi, utile in applicazioni specifiche che richiedono un'elevata efficienza.}
    \label{tab:dijkstra_implementations_comparison}
\end{table}


\clearpage
\subsection{Implementazione Python dell'algoritmo di Dijkstra}
\vspace{2\baselineskip}
\begin{lstlisting}[
    language=Python,
    caption={Implementazione Python dell'algoritmo di Dijkstra per il calcolo delle distanze degli shortest path da una singola sorgente a tutti i vertici raggiungibili in un grafo pesato. Si assume che il metodo \texttt{e.element()} per un arco \texttt{e} rappresenti il peso di quell'arco.},
    captionpos=b,
    label={lst:Dijkstra},
]
def shortest_path_lengths(g, src):
    """Compute shortest-path distances from src to reachable vertices of g.

    Graph g can be undirected or directed, but must be weighted such that
    e.element() returns a numeric weight for each edge e.

    Return dictionary mapping each reachable vertex to its distance from src.
    """
    d = { }                   # d[v] is upper bound from s to v
    cloud = { }               # map reachable v to its d[v] value
    pq = AdaptableHeapPriorityQueue( )  # vertex v will have key d[v]
    pqlocator = { }           # map from vertex to its pq locator

    # for each vertex v of g, add an entry to the priority queue, with
    # the source having distance 0 and all others having infinite distance
    for v in g.vertices( ):
        if v is src:
            d[v] = 0
        else:
            d[v] = float( inf )      # syntax for positive infinity
        pqlocator[v] = pq.add(d[v], v)  # save locator for future updates

    while not pq.is_empty( ):
        key, u = pq.remove_min()
        cloud[u] = key              # its correct d[u] value
        del pqlocator[u]            # u is no longer in pq
        for e in g.incident_edges(u):   # outgoing edges (u,v)
            v = e.opposite(u)
            if v not in cloud:
                # perform relaxation step on edge (u,v)
                wgt = e.element( )
                if d[u] + wgt < d[v]:   # better path to v?
                    d[v] = d[u] + wgt   # update the distance
                    pq.update(pqlocator[v], d[v], v)  # update the pq entry

    return cloud                 # only includes reachable vertices
\end{lstlisting}

\clearpage
\noindent
Il codice visto finora per l'algoritmo di Dijkstra calcola correttamente le distanze minime da una sorgente $s$ a tutti i vertici raggiungibili in un grafo pesato. Tuttavia, in molte applicazioni pratiche, è altrettanto importante poter ricostruire i percorsi effettivi che costituiscono gli shortest path, non solo le loro lunghezze. 

La collezione di tutti gli shortest path che partono dalla sorgente $s$ può essere rappresentata in modo compatto da quella che è nota come \textbf{shortest-path tree}. I percorsi formano un albero radicato perché se uno shortest path da $s$ a $v$ passa attraverso un vertice intermedio $u$, deve necessariamente iniziare con uno shortest path da $s$ a $u$.
In questa sezione, dimostriamo che lo shortest-path tree radicato in $s$ può essere ricostruito in tempo $O(n+m)$, dato l'insieme dei valori $d[v]$ prodotti dall'algoritmo di Dijkstra utilizzando $s$ come sorgente. Come abbiamo fatto quando abbiamo rappresentato gli alberi DFS e BFS, mapperemo ogni vertice $v \neq s$ a un genitore $u$ (eventualmente può essere $u = s$), tale che $u$ è il vertice immediatamente prima di $v$ su uno shortest path da $s$ a $v$. Se $u$ è il vertice subito prima di $v$ sullo shortest path da $s$ a $v$, deve essere che:

$$ d[u] + w(u,v) = d[v] $$

\noindent
Viceversa, se l'equazione sopra è soddisfatta, allora lo shortest path da $s$ a $u$, seguito dall'arco $(u,v)$ è uno shortest path per $v$.
La nostra implementazione presentata di seguito ricostruisce l'albero basandosi su questa logica, testando tutti gli archi entranti per ogni vertice $v$, cercando un $(u,v)$ che soddisfi l'equazione chiave. Il tempo di esecuzione è $O(n+m)$, poiché consideriamo ogni vertice e tutti gli archi entranti a quei vertici.


\vspace{2\baselineskip}
\begin{lstlisting}[
    language=Python,
    caption={Funzione in Python che ricostruisce lo shortest-path tree radicato in un vertice sorgente \texttt{s}, dato il grafo \texttt{g} e la mappa delle distanze \texttt{d} calcolate dall'algoritmo di Dijkstra. La funzione restituisce un dizionario che mappa ogni vertice raggiungibile (diverso da \texttt{s}) all'arco utilizzato per raggiungerlo dal suo genitore nello shortest-path tree.},
    captionpos=b,
    label={lst:Dijkstra_shortest_path_tree},
]
def shortes_path_tree(g, s, d):
    """Reconstruct shortest-path tree rooted at vertex s, given distance map d.

    Return tree as a map from each reachable vertex v (other than s) to the
    edge e=(u,v) that is used to reach v from its parent u in the tree.
    """
    tree = { }
    for v in d:
        if v is not s:
            for e in g.incident_edges(v, False): # consider INCOMING edges
                u = e.opposite(v)
                wgt = e.element( )
                if d[v] == d[u] + wgt:
                    tree[v] = e # edge e is used to reach v
    return tree
\end{lstlisting}


\clearpage
\section{Algoritmo di Bellman-Ford}
L'algoritmo di Dijkstra non garantisce la correttezza della soluzione in presenza di archi con peso negativo all'interno del grafo. Questa limitazione deriva dalla natura \emph{greedy} dell'algoritmo, il quale costruisce l'insieme dei cammini minimi selezionando iterativamente i vertici in ordine non decrescente di distanza.

Il fondamento logico di Dijkstra risiede nell'assunzione che, estendendo un percorso, la distanza totale non possa mai diminuire. Quando un vertice $u$ viene estratto dalla coda di priorità e aggiunto all'insieme dei nodi visitati (soluzione parziale), la sua distanza $D[u]$ è considerata \textbf{definitiva}. Se tutti i pesi sono non negativi ($w \ge 0$), questa assunzione è corretta poiché qualsiasi percorso alternativo che passi per nodi non ancora visitati avrà necessariamente una lunghezza maggiore o uguale a quella attuale.

Tuttavia, l'introduzione di archi con peso negativo invalida questa proprietà. Un arco negativo potrebbe rivelare un percorso "più lungo" in termini di numero di archi, ma con un costo totale inferiore, che passa attraverso nodi che l'algoritmo ha già scartato o finalizzato.
Consideriamo il seguente scenario critico, in riferimento alla Figura \ref{fig:negative_weight}:
\begin{itemize}
    \item Un vertice $C$ viene inserito nella soluzione definitiva con una stima di distanza $D(C) = 5$. Per l'algoritmo, questo valore è ottimale e non verrà più modificato.
    \item Successivamente, l'algoritmo esplora un vertice $F$ e tenta di rilassare l'arco $(F, C)$. Se questo arco ha un peso fortemente negativo, potrebbe esistere un percorso che raggiunge $C$ passando per $F$ con un costo totale inferiore a $D(C)$ precedentemente calcolato (nel nostro caso $1 < 5$).
    \item Poiché l'algoritmo di Dijkstra non riconsidera i vertici già inseriti nell'insieme della soluzione (in quanto l'approccio greedy non consente backtracking), esso ignorerà questo aggiornamento, mantenendo erroneamente $D(C)=5$ invece del valore corretto $1$.
\end{itemize}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.4\textwidth]{immagini/ShortestPath/negative_weight.png}
    \caption{Esempio di grafo con arco a peso negativo che causa un errore nell'algoritmo di Dijkstra.}
    \label{fig:negative_weight}
\end{figure}

\noindent
Per gestire grafi con pesi negativi (purché privi di cicli negativi\footnote{
    Un \textbf{ciclo negativo} è un ciclo (una sequenza chiusa di nodi) il cui peso totale (la somma dei pesi degli archi che lo compongono) è negativo. In presenza di cicli negativi, il concetto di shortest path diventa indefinito, poiché si potrebbe continuare a percorrere il ciclo negativo per ridurre indefinitamente la lunghezza del percorso.
}), è necessario ricorrere ad algoritmi alternativi come \textbf{l'algoritmo di Bellman-Ford}.

