\chapter{Local Search}
\label{cap:LocalSearch}

La \textbf{Local Search} (Ricerca Locale) rappresenta una delle tecniche fondamentali per la risoluzione di problemi di ottimizzazione complessi. A differenza degli algoritmi visti in precedenza, come l'approccio \textit{Greedy} o la \textit{Programmazione Dinamica}, che costruiscono la soluzione da zero, la ricerca locale opera su soluzioni complete. L'idea centrale è partire da una soluzione completa iniziale (spesso generata casualmente o ricavata da semplici euristiche) e migliorarla iterativamente esplorando un "intorno" locale di soluzioni simili.

L'ottimizzazione di un problema può essere rappresentata graficamente come una curva o superficie in cui ogni punto corrisponde ad una soluzione del problema e la sua “altezza” rappresenta il costo associato a quella soluzione. Il problema diventa quello di individuare il punto più basso possibile, ovvero il minimo costo per quel problema di ottimizzazione.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.3\textwidth]{immagini/LocalSearch/curva1.png}
    \caption{Rappresentazione grafica della curva delle soluzioni in un problema di ottimizzazione.}
    \label{fig:local_search_landscape}
\end{figure}

\noindent
Formalmente, consideriamo un problema di ottimizzazione definito da:
\begin{itemize}
    \item $C$: l'insieme delle soluzioni ammissibili.
    \item $c$: una funzione di costo che associa ad ogni soluzione $S \in C$ un valore reale $c(S)$.
    \item $N$: una funzione che definisce l'intorno di una soluzione, ovvero l'insieme delle soluzioni "vicine" a $S$, denotato come $N(S) \subseteq C$.
\end{itemize}

\noindent
Graficamente, possiamo immaginare lo spazio delle soluzioni come un paesaggio: le soluzioni sono le coordinate e il costo è l'altitudine. L'algoritmo cerca di scendere verso il punto più basso (la valle più profonda).

\clearpage
\noindent
A questo proposito, una distinzione cruciale è quella tra ottimi locali e globali:
\begin{itemize}
    \item Un \textbf{Minimo Globale} è una soluzione $S^*$ con costo minimo assoluto su tutto $C$.
    \item Un \textbf{Minimo Locale} è una soluzione $S$ tale che $c(S) \leq c(S')$ per ogni vicino $S' \in N(S)$.
    \item Il problema principale della ricerca locale è che l'algoritmo può rimanere intrappolato in un minimo locale, incapace di "vedere" una soluzione migliore che si trova oltre una "collina" di costi crescenti.
\end{itemize}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.3\textwidth]{immagini/LocalSearch/curva2.png}
    \caption{La ricerca locale esplora l'intorno delle soluzioni per trovare minimi locali e globali.} 
    \label{fig:local_vs_global_minimum}
\end{figure}

\noindent
Ad ogni iterazione, l'algoritmo di ricerca mantiene una soluzione corrente $S \in C$. Ad ogni step, sceglie un vicino $S'$ di $S$, dichiara $S'$ come nuova soluzione corrente se $c(S') \leq c(S)$, e itera. Durante l'esecuzione dell'algoritmo, ricorda la soluzione a costo minimo che ha visto finora, $S^*$; quindi, man mano che procede, trova soluzioni sempre migliori e aggiorna $S^*$ di conseguenza. L'algoritmo termina quando non riesce più a trovare un vicino$S'$ migliore della soluzione corrente $S$, restituendo $S^*$ come soluzione finale.

Il \emph{punto cruciale} di un algoritmo di ricerca locale risiede nella scelta della \textbf{neighbor relation} (relazione di vicinato) e nella progettazione della regola per scegliere una soluzione vicina ad ogni passo. Da un lato, la neighbor relation deve essere sufficientemente ampia da permettere all'algoritmo di uscire da minimi locali indesiderati; dall'altro, deve essere sufficientemente ristretta da mantenere l'efficienza computazionale dell'algoritmo.

A differenza dell'approccio Greedy, la ricerca locale permette di rivalutare le scelte fatte in precedenza (come già detto, si parte da una soluzione iniziale completa ma non necessariamente buona) e di esplorare soluzioni alternative. Questo rende la ricerca locale particolarmente adatta per problemi complessi dove le soluzioni ottimali sono difficili da trovare direttamente. 
Il vantaggio dunque è che con Greedy si può facilmente incappare in qualche minimo locale senza possibilità di uscirne, mentre con la ricerca locale si ha la possibilità di esplorare l'intorno delle soluzioni e potenzialmente trovare soluzioni migliori.

Va detto però che un algoritmo di ricerca locale che sia efficiente non esiste per tutti i problemi di ottimizzazione.

\clearpage
\section{Vertex Cover}
Consideriamo il problema del \textbf{Vertex Cover}. Siano dati un insieme $V$ di elementi e un insieme $E$ di coppie di elementi di $V$ (tutte le coppie di $E$ sono distinte, cioè differiscono almeno per un elemento). L'insieme $C$ delle possibili soluzioni è dato da tutti i sottoinsiemi (soluzioni) $S$ di $V$ tali che ogni coppia in $E$ ha almeno un elemento in $S$. Il costo di una soluzione $S$ è semplicemente la sua cardinalità, cioè il numero di elementi in $S$: $c(S) = |S|$.

In altre parole, un \textbf{Vertex Cover} è un sottoinsieme $S \subseteq V$ che ``copre'' tutte le coppie in $E$: questo significa che, per ogni coppia presente in $E$, \textbf{almeno uno dei due elementi} che la compongono deve appartenere alla soluzione $S$.



\paragraph{Esempio:} $V = \{\text{a,b,c,d,e}\}$ e $E = \{\text{(a,b), (a,c), (b,d), (c,d), (d,e)}\}$. Dei possibili Vertex Cover sono $S = \{\text{b,c,e}\}$, poiché ogni coppia in $E$ contiene almeno uno degli elementi in $S$, e il costo di questa soluzione è $c(S) = 3$. Un altro possibile Vertex Cover è $S' = \{\text{a,d}\}$, con costo $c(S') = 2$, che è migliore della soluzione precedente. Se prendiamo $S = \{\text{b,c}\}$, questa non è una soluzione valida perché la coppia (d,e) non è coperta.

\vspace{1\baselineskip}
\noindent
Per applicare la ricerca locale al problema del Vertex Cover, dobbiamo definire una \emph{neighbor relation} efficace. Una semplice relazione può essere considerare come vicini due soluzioni che differiscono per l'aggiunta o la rimozione di un singolo elemento da $V$. In questo modo, ciascuna soluzione $S$ ha $n$ vicini, dove $n$ è la dimensione di $V$.
\begin{itemize}
    \item È semplice notare questa proprietà considerando un esempio: se $V = \{\text{a,b,c,d,e}\}$ e $S = \{\text{b,c,e}\}$, i vicini di $S$ sono: $\text\{a,b,c,e\}, \text\{b,c,d,e\}, \text\{c,e\}, \text\{b,e\}, \text\{b,c\}$.
\end{itemize}


\subsection{Gradient Descent per Vertex Cover}
L'algoritmo di ricerca locale più semplice possibile è il \textbf{Gradient Descent} (Discesa del Gradiente). In questo approccio, ad ogni iterazione, abbiamo una soluzione corrente $S$ e l'algoritmo esplora tutti i suoi vicini per poi scegliere il vicino $S'$ con il costo più basso tra quelli che migliorano la soluzione corrente (cioè quelli con $c(S') < c(S)$). Se non esistono vicini migliori, l'algoritmo termina e restituisce la soluzione corrente come risultato finale.

Questo algoritmo è semplice ma può facilmente rimanere intrappolato in minimi lodali, poiché esplora solo i vicini che migliorano la soluzione corrente. Nel contesto del problema Vertex Cover, consideriamo un insieme $V$ di elementi e un insieme $E$ di coppie. L'algoritmo Gradient Descent viene inizializzato con $S=V$ e procede rimuovendo un elemento per volta fintanto che la condizione di copertura delle coppie rimane soddisfatta.

Per valutare l'efficacia dell'algoritmo, analizziamo il suo comportamento in tre scenari distinti. Mentre l'approccio funziona correttamente in casi banali, mostra evidenti limiti e tendenza a bloccarsi in minimi locali non appena la struttura delle coppie diventa più complessa:

\clearpage
\begin{itemize}
    \item \textbf{Caso banale (Insieme $E$ vuoto):} Se non ci sono coppie da coprire, l'algoritmo rimuove correttamente tutti gli elementi fino a raggiungere l'insieme vuoto, che rappresenta il minimo globale.
    
    \item \textbf{Caso dell'Elemento "Centro":} Supponiamo che esista un elemento speciale $c \in V$ tale che $c$ è contenuto in ogni coppia di $E$.
    \begin{itemize}
        \item La soluzione ottima è data dal singleton $\{c\}$.
        \item Se l'algoritmo rimuove $c$ nelle prime iterazioni, sarà costretto a mantenere in $S$ tutti gli altri elementi accoppiati con $c$ per garantire la copertura. Si raggiunge così un \textit{minimo locale} molto più costoso dell'ottimo globale, da cui non è possibile uscire poiché l'algoritmo non permette di reinserire elementi (poiché l'algoritmo aggiorna la soluzione solo se il costo diminuisce; il costo è dato dal numero di elementi in $S$ che quindi può solo diminuire).
    \end{itemize}
    
    \item \textbf{Caso delle Coppie Sequenziali:} Consideriamo $V = \{v_1, \dots, v_n\}$ con coppie definite come $E = \{(v_1, v_2), (v_2, v_3), \dots, (v_{n-1}, v_n)\}$.
    \begin{itemize}
        \item La soluzione ottima consiste nel selezionare elementi alternati (es. $\{v_2, v_4, \dots\}$), ottenendo una cardinalità di circa $(n-1)/2$ .
        \item L'algoritmo può invece convergere su minimi locali inefficienti, come ad esempio la configurazione $\{v_1, v_2, v_4, v_5, \dots\}$. Questa soluzione è valida e non riducibile (rimuovere un elemento scoprirebbe una coppia), ma ha una cardinalità di circa $2n/3$, risultando significativamente peggiore dell'ottimo .
    \end{itemize}
\end{itemize}






\section{Algoritmo Metropolis}
Come abbiamo visto con il Gradient Descent, l'approccio puramente "greedy" (che accetta solo miglioramenti) tende a rimanere intrappolato nei minimi locali. Per risolvere questo problema, è necessario introdurre un meccanismo che permetta all'algoritmo di accettare occasionalmente soluzioni peggiori, nella speranza che queste mosse "in salita" (uphill) permettano di scavalcare le barriere dei minimi locali e raggiungere il minimo globale.

Questa intuizione è alla base dell'\textbf{Algoritmo Metropolis}, che simula il comportamento di un sistema fisico basandosi sui principi della meccanica statistica.
L'idea fondamentale è che il processo di ricerca sia globalmente orientato verso passi "in discesa" (miglioramento del costo), ma occasionalmente compia passi "in salita" per uscire dai minimi locali.

\clearpage
\subsection{La Funzione di Gibbs-Boltzmann}
L'algoritmo utilizza un'analogia fisica in cui ogni soluzione ammissibile $S$ corrisponde a uno stato del sistema, e la funzione di costo $c(S)$ corrisponde all'\emph{energia} $E$ di quello stato.
La probabilità di trovare il sistema in un determinato stato con energia $E$ è modellata dalla \textbf{funzione di Gibbs-Boltzmann}:

$$
    e^{-E / (kT)}
$$

\begin{itemize}[nosep]
    \item $E$ è l'energia (il costo) dello stato corrente.
    \item $T > 0$ è la \emph{temperatura} del sistema.
    \item $k$ è una costante (costante di Boltzmann).
    \item La funzione rappresenta una probabilità, e infatti assume valori tra $0$ e $1$.
\end{itemize}

\vspace{1\baselineskip}
\noindent
Questa funzione è monotona decrescente rispetto all'energia $E$: ciò significa che il sistema ha una probabilità maggiore di trovarsi in stati a bassa energia (basso costo) rispetto a stati ad alta energia.
Il parametro $T$ (temperatura) gioca un ruolo cruciale nel determinare il comportamento del sistema:
\begin{itemize}
    \item \textbf{Se $T$ è grande:} stati ad alta e bassa energia hanno approssimativamente la stessa probabilità. L'algoritmo esplora lo spazio delle soluzioni quasi casualmente.
    \item \textbf{Se $T$ è piccolo:} gli stati a bassa energia sono molto più probabili. Il sistema tende a cristallizzarsi verso i minimi.
\end{itemize}

\subsection{Funzionamento dell'Algoritmo}
L'algoritmo Metropolis utilizza questa distribuzione di probabilità per decidere se accettare o meno una nuova soluzione.
Fissata una temperatura $T$, l'algoritmo mantiene uno stato corrente $S$ e procede come segue:

\begin{enumerate}[nosep]
    \item Viene generata una perturbazione casuale dello stato corrente $S$ per ottenere un nuovo stato vicino $S' \in N(S)$.
    \item Si calcola la variazione di energia (costo): $\Delta E = E(S') - E(S)$.
    \item \textbf{Se $E(S') \le E(S)$:} la nuova soluzione è migliore (o uguale). L'algoritmo accetta sempre il cambiamento e aggiorna lo stato corrente a $S'$.
    \item \textbf{Altrimenti ($E(S') > E(S)$):} la nuova soluzione è peggiore ($\Delta E > 0$). L'algoritmo accetta il nuovo stato $S'$ solo con una certa probabilità, data da:
    $$
        \mathbb{P}(\text{accettare } S') = e^{-\frac{\Delta E}{kT}}
    $$
\end{enumerate}

\noindent
L'intuizione fondamentale è che il processo di ricerca non è casuale ma pesato: in accordo con la distribuzione di Gibbs-Boltzmann, l'algoritmo tende a soffermarsi con maggiore frequenza negli stati a basso costo. Di conseguenza, pur potendo accettare peggioramenti momentanei, il sistema privilegia statisticamente le zone migliori, aumentando la probabilità di convergere verso l'ottimo globale.







\clearpage
\section{Simulated Annealing}
Il \textbf{Simulated Annealing} (Ricottura Simulata) rappresenta un'evoluzione dell'algoritmo Metropolis. 
È fondamentale sottolineare che il meccanismo di decisione rimane invariato: il Simulated Annealing utilizza la \textbf{stessa funzione di Gibbs-Boltzmann} vista in precedenza per calcolare la probabilità di accettare una mossa peggiorativa ($\Delta E > 0$):

$$
    \mathbb{P}(\text{accettare } S') = e^{-\frac{\Delta E}{kT}}
$$

\noindent
Mentre nell'algoritmo Metropolis la temperatura $T$ è costante, il Simulated Annealing introduce una variazione dinamica del parametro $T$ per bilanciare esplorazione e sfruttamento.

\noindent
Il comportamento dell'algoritmo cambia drasticamente in funzione della temperatura:
\begin{itemize}
    \item \textbf{Se $T$ è grande:} la probabilità di accettare una mossa "in salita" (peggiorativa) è molto alta. In questa fase l'algoritmo esplora lo spazio quasi liberamente.
    \item \textbf{Se $T$ è piccolo:} le mosse in salita non vengono quasi mai accettate. L'algoritmo si comporta in modo simile al Gradient Descent, raffinando la soluzione locale.
\end{itemize}

\noindent
L'idea centrale è quella di utilizzare una "manopola" per controllare $T$ durante l'esecuzione.
Si definisce quindi una \textbf{Cooling Schedule} (piano di raffreddamento), ovvero una funzione $T(i)$ che determina il valore della temperatura all'iterazione $i$-esima, decrescendo progressivamente.

\paragraph{Analogia Fisica.}
Il nome e il funzionamento dell'algoritmo derivano direttamente dal processo fisico di ricottura (\emph{annealing}) dei materiali cristallini:
\begin{itemize}
    \item Se portiamo un solido ad alta temperatura, l'agitazione termica rompe i legami e non ci aspettiamo che mantenga una struttura cristallina ordinata.
    \item Se prendiamo un solido fuso e lo "congeliamo" molto bruscamente (raffreddamento rapido), le molecole non hanno il tempo di riorganizzarsi e non otterremo un cristallo perfetto, ma un solido amorfo o con difetti (metafora del minimo locale).
    \item L'\textbf{Annealing} (ricottura) consiste invece nel raffreddare il materiale gradualmente partendo da alte temperature. Questo permette al sistema di raggiungere l'equilibrio termico attraverso una successione di stati a temperatura intermedia, permettendo agli atomi di disporsi nella configurazione a minima energia (metafora del minimo globale).
\end{itemize}

\noindent
Nello stesso modo, il Simulated Annealing parte con $T$ alta per evitare di rimanere intrappolato subito in minimi locali, e abbassa $T$ lentamente per permettere all'algoritmo di convergere verso il minimo globale.

\vspace{1\baselineskip}
\noindent
Da sottolineare che \textbf{nessuna di queste tecniche garantisce di trovare sempre la soluzione ottima}, ma il Simulated Annealing, se opportunamente configurato (scelta della cooling schedule e del numero di iterazioni), funziona meglio rispetto all'algoritmo Metropolis o al Gradient Descent puro.




\clearpage
\section{Max Cut}
Un altro classico problema di ottimizzazione combinatoria che ben si presta all'approccio della ricerca locale è il \textbf{Max Cut}.
A differenza del problema del Vertex Cover, dove l'obiettivo era minimizzare un costo, nel Max Cut l'obiettivo è \textbf{massimizzare} il valore della soluzione.

\begin{itemize}
    \item Sia dato un insieme $V$ di elementi (nodi) e un insieme $E$ di coppie di elementi (archi). Ogni coppia $e \in E$ possiede un peso positivo $w_e > 0$.
    \item L'insieme $C$ delle soluzioni ammissibili è costituito da tutte le possibili \textbf{partizioni} di $V$ in due insiemi disgiunti $(A, B)$ tali che $A \cup B = V$ e $A \cap B = \emptyset$.
    \item Una coppia $(u, v) \in E$ si dice "tagliata" (cut pair) se i due elementi appartengono a insiemi diversi della partizione (uno in $A$ e l'altro in $B$).
    \item Il \textbf{cut value} (costo o valore) di una soluzione è la somma dei pesi delle coppie tagliate dalla partizione. L'obiettivo è trovare la partizione $(A, B)$ che massimizzi questo costo totale.
\end{itemize}


\paragraph{Esempio.}
Consideriamo il seguente scenario:
\begin{itemize}
    \item $V = \{a, b, c, d, e\}$
    \item $E = \{(a,b, 2), (a,c, 4), (b,d, 3), (c,d, 5), (d,e, 3)\}$
\end{itemize}

\noindent
Analizziamo alcune partizioni per capire come calcolare il costo e distinguere soluzioni valide da quelle non valide:
\begin{itemize}
    \item \textbf{Una soluzione valida (massimo locale):} $(\{a,b\}, \{c,d,e\})$. $ \text{Costo} = 4 + 3 = 7 $.
    \item \textbf{Una soluzione non valida:} $(\{a,b\}, \{c,d\})$. Questa non è una soluzione ammissibile perché il nodo $e$ non è stato assegnato a nessuno dei due insiemi (l'unione non è $V$).
    \item \textbf{La soluzione ottima (massimo globale):} $(\{a,d\}, \{b,c,e\})$. $ \text{Costo Ottimo} = 2 + 4 + 3 + 5 + 3 = 17 $.
\end{itemize}

\noindent
È doveroso fare una precisazione sulla complessità computazionale del problema.
Sebbene in linea teorica sia sempre possibile determinare la soluzione ottima enumerando tutte le $2^{|V|}$ possibili partizioni (approccio \textit{Brute Force}), tale metodo diviene rapidamente inapplicabile all'aumentare del numero di nodi a causa dell'esplosione combinatoria.
Dunque, per il problema del Max Cut, così come per altri particolari problemi di ottimizzazione, non esiste alcun algoritmo noto in grado di trovare la soluzione ottima in \textbf{tempo polinomiale} rispetto alla dimensione dell'input.
Di conseguenza, per istanze di dimensioni significative, la ricerca della soluzione esatta è computazionalmente intrattabile, rendendo necessario l'utilizzo di algoritmi di approssimazione o euristiche (come la Local Search) che forniscano soluzioni di buona qualità, pur senza garanzia di ottimalità assoluta.

\clearpage
\noindent
Per applicare la ricerca locale, definiamo una neighbor relation semplice ed efficace.

\paragraph{Single-flip Neighborhood.}
Data una partizione corrente $(A, B)$, una partizione vicina (neighbor) si ottiene spostando esattamente un nodo da un insieme all'altro.
Questa operazione è chiamata "single-flip".

\paragraph{Algoritmo Greedy.}
Possiamo implementare un semplice algoritmo Greedy (o di ascesa del gradiente - Gradient Ascent -, dato che stiamo massimizzando) basato su questo vicinato:
\begin{enumerate}
    \item Si inizia con una partizione casuale $(A, B)$.
    \item Si cerca un nodo $v$ che, se spostato nell'altro insieme, aumenta il costo totale del taglio (nodo migliorativo).
    \item Se tale nodo esiste:
    \begin{itemize}
        \item Se $v \in A$, spostalo in $B$.
        \item Altrimenti, spostalo in $A$.
    \end{itemize}
    \item Si ripete il passo 2 finché non esistono più nodi che migliorano la soluzione (raggiungimento di un ottimo locale).
    \item Si restituisce la partizione finale $(A, B)$.
\end{enumerate}

\noindent
Anche in questo caso, l'approccio Greedy può bloccarsi in ottimi locali. Per ottenere risultati migliori, si possono applicare le euristiche viste in precedenza, come il Simulated Annealing, o definire intorni più complessi che spostano più nodi contemporaneamente.

\vspace{1\baselineskip}
\noindent
Finora abbiamo ipotizzato di muoverci nello spazio delle soluzioni spostando un singolo nodo alla volta. Tuttavia, la scelta della dimensione e della struttura del vicinato è determinante per la qualità della soluzione finale e per il tempo di esecuzione. Più ampio è il vicinato, minore è il rischio di bloccarsi in minimi locali, ma maggiore è il costo computazionale per esplorarlo.

\noindent
Possiamo distinguere tre tipologie principali di vicinato:

\begin{itemize}
    \item \textbf{1-flip neighborhood:} È il vicinato base utilizzato nell'algoritmo Greedy sopra descritto. Due partizioni $(A, B)$ e $(A', B')$ sono vicine se differiscono per la posizione di \textbf{esattamente un nodo}.
    
    \item \textbf{k-flip neighborhood:} È una generalizzazione del precedente. Due partizioni sono considerate vicine se differiscono per \textbf{al più $k$ nodi}.
    \begin{itemize}[nosep]
        \item Questo approccio permette di scavalcare minimi locali che richiederebbero lo spostamento simultaneo di più elementi.
        \item Tuttavia, il numero di vicini cresce come $\Theta(n^k)$. Questo rende l'esplorazione computazionalmente proibitiva (troppo costosa) per valori di $k$ elevati.
    \end{itemize}
    
    \item \textbf{KL-neighborhood (Kernighan-Lin):} Rappresenta un approccio sofisticato che permette di esplorare configurazioni molto distanti senza il costo esponenziale del k-flip.
\end{itemize}


\clearpage
\paragraph{L'approccio Kernighan-Lin.}
L'intuizione di Kernighan-Lin è quella di costruire un vicinato complesso attraverso una sequenza di mosse guidate. L'idea chiave è accettare temporaneamente partizioni con un \textbf{cut value} inferiore, pur di uscire da un ottimo locale ed esplorare configurazioni che potrebbero rivelarsi migliori a lungo termine.

\noindent
Per generare i vicini di una partizione iniziale $(A, B)$, si procede nel seguente modo:
\begin{itemize}
    \item \textbf{Iterazione 1:} Si valuta lo spostamento di ogni singolo nodo (da $A$ a $B$ o viceversa). Tra tutte le possibili mosse, si sceglie quella che porta alla nuova partizione $(A_1, B_1)$ con il \textbf{cut value} più alto tra quelle disponibili.
    \begin{itemize}
        \item \emph{Punto cruciale:} Si seleziona la mossa che massimizza il cut value corrente, \textbf{anche se questo valore è inferiore} rispetto a quello della configurazione di partenza $(A, B)$.
        \item In altre parole: se tutte le mosse possibili peggiorano la soluzione, scegliamo quella che la peggiora di meno. Questo passo è fondamentale per permettere all'algoritmo di "scendere" da un massimo locale per poi risalire verso uno globale.
    \end{itemize}
    Il nodo appena spostato viene "marcato" (bloccato) e non potrà essere mosso nuovamente in questa fase.
    
    \item \textbf{Iterazioni successive ($i > 1$):} Si ripete il procedimento considerando esclusivamente i nodi \textbf{non ancora marcati} (ovvero quelli che non sono stati spostati nelle iterazioni precedenti).
    Partendo dalla configurazione corrente $(A_{i-1}, B_{i-1})$, si valuta lo spostamento di ciascun nodo disponibile e si sceglie quello che risulta nel miglior \textbf{cut value} per la nuova configurazione $(A_i, B_i)$.
    \begin{itemize}
        \item Anche in questo caso, la scelta ricade sulla mossa migliore possibile al momento tra i nodi residui, indipendentemente dal fatto che il cut value aumenti o diminuisca rispetto al passo precedente.
        \item Il nodo scelto viene spostato e marcato.
    \end{itemize}
    
    \item \textbf{Conclusione della sequenza:} Il processo continua iterativamente finché \textbf{tutti} i nodi sono stati spostati e marcati esattamente una volta.
    Questo genera una sequenza ordinata di partizioni $(A_1, B_1), \dots, (A_{n}, B_{n})$. Nota che l'ultima partizione $(A_n, B_n)$ avrà tutti i nodi scambiati rispetto all'inizio (è la partizione speculare).
\end{itemize}

\noindent
Il "vicinato" KL è costituito dall'insieme di tutte queste partizioni intermedie generate. L'algoritmo di ricerca locale esamina questa sequenza e si sposta nella configurazione $(A_k, B_k)$ che ha il valore di taglio massimo tra tutte quelle generate.
In pratica, questo metodo permette di eseguire una lunga sequenza di flip in un singolo passo logico dell'algoritmo, risultando un framework estremamente potente ed efficace.






\clearpage
\section{Hopfield Neural Networks}


